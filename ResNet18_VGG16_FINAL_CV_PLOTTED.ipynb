{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00211924",
   "metadata": {},
   "source": [
    "### 📦 第 0 格：导入必要的库\n",
    "导入了如 `torch`, `cv2`, `numpy`, `matplotlib`, `tqdm`, `torchvision.transforms` 等用于图像处理、模型构建、训练可视化所需的基础包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f561b7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # 导入库\n",
    "import cv2  # 导入库\n",
    "import torch  # 导入库\n",
    "import random  # 导入库\n",
    "import numpy as np  # 导入库\n",
    "import matplotlib.pyplot as plt  # 导入库\n",
    "from tqdm import tqdm\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d75154",
   "metadata": {},
   "source": [
    "### ⚙️ 第 1 格：超参数配置\n",
    "定义模型名称、训练轮数、批大小、学习率、测试集比例等训练配置参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ccc34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数设置\n",
    "config = {  # 设置模型训练的超参数\n",
    "    \"model_name\": \"resnet\",  # 可选 \"resnet\" 或 \"vgg\"\n",
    "    \"num_epochs\": 15,\n",
    "    \"batch_size\": 32,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"test_size\": 0.2,\n",
    "    \"sample_ratio\": 1.0\n",
    "}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset_path = \"Aerial_Landscapes/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1a4663",
   "metadata": {},
   "source": [
    "### 🧠 第 2 格：模型初始化函数\n",
    "根据传入的模型名（resnet 或 vgg）初始化预训练模型并替换输出层以匹配数据集类别数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfaf865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, use_pretrained=True):\n",
    "    input_size = 224\n",
    "    if model_name == \"resnet\":\n",
    "        model = models.resnet18(pretrained=use_pretrained)  # 初始化 ResNet 模型\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)  # 使用ResNet18\n",
    "    elif model_name == \"vgg\":\n",
    "        model = models.vgg16(pretrained=use_pretrained)  # 初始化 VGG 模型\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(\"不支持的模型名称，请选择 'resnet' 或 'vgg'\")\n",
    "    return model, input_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d858df1b",
   "metadata": {},
   "source": [
    "### 🧱 第 3 格：图像预处理流程\n",
    "定义训练和测试图像所使用的图像增强与归一化操作，包括随机裁剪、缩放、标准化等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e231d89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(input_size=224):\n",
    "    train_transform = transforms.Compose([  # 定义图像预处理管道\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    # === 替换后的 test_transform: 加入模糊+噪声增强 ===\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((input_size, input_size)),\n",
    "        transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0)),  # ✅ 添加高斯模糊\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: x + 0.05 * torch.randn_like(x)),    # ✅ 添加高斯噪声\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "# 原始 test_transform 被覆盖\n",
    "# test_transform = transforms.Compose([  # 定义图像预处理管道\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    return train_transform, test_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dc70b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ✅ 定义遮挡函数：将图像中心区域遮成黑色，模拟遮挡情况\n",
    "import torchvision.transforms.functional as TF\n",
    "from PIL import ImageDraw\n",
    "\n",
    "class RandomOcclusion:\n",
    "    def __init__(self, size=(60, 60)):\n",
    "        self.size = size  # 遮挡块尺寸\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # 假设 img 是 PIL Image\n",
    "        w, h = img.size\n",
    "        x0 = w // 2 - self.size[0] // 2\n",
    "        y0 = h // 2 - self.size[1] // 2\n",
    "        x1 = x0 + self.size[0]\n",
    "        y1 = y0 + self.size[1]\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        draw.rectangle([x0, y0, x1, y1], fill=(0, 0, 0))\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abe6003",
   "metadata": {},
   "source": [
    "\n",
    "### 🧪 鲁棒性实验 2：图像遮挡测试\n",
    "\n",
    "我们在测试集 transform 中加入 `RandomOcclusion` 操作，即在图像中心区域添加黑色遮挡块，用于模拟现实中摄像头被遮挡或图像不完整的情况。\n",
    "通过评估模型在遮挡条件下的表现，可以测试其鲁棒性。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604147e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ✅ 应用遮挡增强 transform（测试时使用）\n",
    "occluded_test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    RandomOcclusion(size=(60, 60)),                     # 加遮挡块\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2e50eb",
   "metadata": {},
   "source": [
    "### 🗂️ 第 4 格：自定义 PyTorch 数据集类\n",
    "用于将图像和标签组合为 Dataset 对象，以便后续使用 DataLoader 加载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99c2528",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):  # 自定义数据集类\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759792e1",
   "metadata": {},
   "source": [
    "### 🧪 第 5 格：数据加载和划分函数\n",
    "从指定文件夹加载图像数据，并按设定比例划分为训练集和测试集，同时返回类别标签映射。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564eb13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split_dataset(root_dir, test_size=0.2, sample_ratio=1.0):\n",
    "    classes = sorted(os.listdir(root_dir))\n",
    "    class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "    train_images, train_labels = [], []\n",
    "    test_images, test_labels = [], []\n",
    "\n",
    "    for cls_name in classes:\n",
    "        cls_path = os.path.join(root_dir, cls_name)\n",
    "        img_files = [os.path.join(cls_path, f) for f in os.listdir(cls_path) if f.endswith('.jpg')]\n",
    "        random.seed(42)\n",
    "        random.shuffle(img_files)\n",
    "        n_samples = int(len(img_files) * sample_ratio)\n",
    "        split = int(n_samples * (1 - test_size))\n",
    "        imgs = img_files[:n_samples]\n",
    "        train_imgs = imgs[:split]\n",
    "        test_imgs = imgs[split:]\n",
    "        train_images.extend([cv2.imread(p) for p in train_imgs])\n",
    "        train_labels.extend([class_to_idx[cls_name]] * len(train_imgs))\n",
    "        test_images.extend([cv2.imread(p) for p in test_imgs])\n",
    "        test_labels.extend([class_to_idx[cls_name]] * len(test_imgs))\n",
    "\n",
    "    return (train_images, train_labels), (test_images, test_labels), classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de969d42",
   "metadata": {},
   "source": [
    "### 🔁 第 6 格：ResNet/VGG 训练函数\n",
    "包括训练循环、Early Stopping、loss 和 acc 的记录，并在训练完成后绘制学习曲线图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc41c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, device, train_loader, test_loader, criterion, optimizer,  # 定义 ResNet/VGG 通用训练函数\n",
    "                num_epochs=25, checkpoint_path='checkpoint.pth', patience=5):\n",
    "\n",
    "    best_acc = 0.0\n",
    "    epochs_no_improve = 0\n",
    "    early_stop = False\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [],\n",
    "        'test_loss': [], 'test_acc': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "        for batch in train_loader_tqdm:\n",
    "            if early_stop:\n",
    "                print(f\"⚠️ 早停触发于第 {epoch+1} 轮\")\n",
    "                break\n",
    "\n",
    "        model.train()\n",
    "        train_loss, correct_train, total_train = 0.0, 0, 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_train += torch.sum(preds == labels.data)\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "        epoch_train_loss = train_loss / total_train\n",
    "        epoch_train_acc = correct_train.double() / total_train\n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "        history['train_acc'].append(epoch_train_acc.item())\n",
    "\n",
    "        model.eval()\n",
    "        test_loss, correct_test, total_test = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                test_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct_test += torch.sum(preds == labels.data)\n",
    "                total_test += labels.size(0)\n",
    "\n",
    "        epoch_test_loss = test_loss / total_test\n",
    "        epoch_test_acc = correct_test.double() / total_test\n",
    "        history['test_loss'].append(epoch_test_loss)\n",
    "        history['test_acc'].append(epoch_test_acc.item())\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Acc={epoch_train_acc:.4f}, Test Acc={epoch_test_acc:.4f}\")\n",
    "\n",
    "        if epoch_test_acc > best_acc:\n",
    "            best_acc = epoch_test_acc\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                early_stop = True\n",
    "\n",
    "    return model, history\n",
    "    # ✅ 添加训练与验证的损失/准确率曲线图像\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history['train_loss'], label='Train Loss', c='red')\n",
    "    plt.plot(history['test_loss'], label='Val Loss', c='blue')\n",
    "    plt.xlabel('Epochs'); plt.ylabel('Loss'); plt.legend(); plt.title('Loss Curve')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history['train_acc'], label='Train Acc', c='orangered')\n",
    "    plt.plot(history['test_acc'], label='Val Acc', c='green')\n",
    "    plt.xlabel('Epochs'); plt.ylabel('Accuracy'); plt.legend(); plt.title('Accuracy Curve')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70a002e",
   "metadata": {},
   "source": [
    "### 📊 第 7 格：评估函数\n",
    "对模型在测试集上的表现进行评估，生成预测值与真实值列表，可用于后续可视化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7603de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, class_names):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            y_true.extend(labels)\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(xticks_rotation='vertical', cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1b9dfb",
   "metadata": {},
   "source": [
    "### 🧪 第 8 格：加载数据集\n",
    "调用数据加载函数并获取训练图像、测试图像、类别标签等信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372ef615",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels), classes = load_and_split_dataset(\n",
    "    dataset_path,\n",
    "    test_size=config[\"test_size\"],  # 设置模型训练的超参数\n",
    "    sample_ratio=config[\"sample_ratio\"]  # 设置模型训练的超参数\n",
    ")\n",
    "\n",
    "model, input_size = initialize_model(\n",
    "    model_name=config[\"model_name\"],  # 设置模型训练的超参数\n",
    "    num_classes=len(classes),\n",
    "    use_pretrained=True\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "train_transform, test_transform = get_transforms(input_size)\n",
    "\n",
    "train_dataset = CustomDataset(train_images, train_labels, train_transform)\n",
    "test_dataset = CustomDataset(test_images, test_labels, test_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)  # 设置模型训练的超参数\n",
    "test_loader = DataLoader(test_dataset, batch_size=config[\"batch_size\"], shuffle=False)  # 设置模型训练的超参数\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])  # 设置模型训练的超参数\n",
    "\n",
    "model, history = train_model(\n",
    "    model, device, train_loader, test_loader,\n",
    "    criterion, optimizer,\n",
    "    num_epochs=config[\"num_epochs\"],  # 设置模型训练的超参数\n",
    "    patience=5\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        y_true.extend(labels)\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=classes, digits=4)\n",
    "print(\"Evaluation Metrics (Precision, Recall, F1-score):\\n\")\n",
    "print(report)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "plt.figure(figsize=(12, 10))\n",
    "disp.plot(xticks_rotation=45, cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53773f0f",
   "metadata": {},
   "source": [
    "### ▶️ 第 9 格：run_and_evaluate 函数\n",
    "这是一个便捷函数，用于初始化模型、训练并评估结果，适用于快速比较多个模型表现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a96506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_evaluate(model_name, classes):  # 执行模型训练和评估\n",
    "    (train_images, train_labels), (test_images, test_labels), _ = load_and_split_dataset(\n",
    "        dataset_path,\n",
    "        test_size=config[\"test_size\"],  # 设置模型训练的超参数\n",
    "        sample_ratio=config[\"sample_ratio\"]  # 设置模型训练的超参数\n",
    "    )\n",
    "\n",
    "    model, input_size = initialize_model(\n",
    "        model_name=model_name,\n",
    "        num_classes=len(classes),\n",
    "        use_pretrained=True\n",
    "    )\n",
    "    model = model.to(device)\n",
    "\n",
    "    train_transform, test_transform = get_transforms(input_size)\n",
    "\n",
    "    train_dataset = CustomDataset(train_images, train_labels, train_transform)\n",
    "    test_dataset = CustomDataset(test_images, test_labels, test_transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)  # 设置模型训练的超参数\n",
    "    test_loader = DataLoader(test_dataset, batch_size=config[\"batch_size\"], shuffle=False)  # 设置模型训练的超参数\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])  # 设置模型训练的超参数\n",
    "\n",
    "    model, _ = train_model(\n",
    "        model, device, train_loader, test_loader,\n",
    "        criterion, optimizer,\n",
    "        num_epochs=config[\"num_epochs\"],  # 设置模型训练的超参数\n",
    "        patience=5\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            y_true.extend(labels)\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    report = classification_report(y_true, y_pred, target_names=classes, digits=4)\n",
    "    print(f\"===== {model_name.upper()} Evaluation Metrics =====\\n\")\n",
    "    print(report)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    disp.plot(xticks_rotation=45, cmap='Blues')\n",
    "    plt.title(f\"Confusion Matrix for {model_name.upper()}\")\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a00fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔍 正在比较 ResNet18 与 VGG16 的分类性能...\\n\")\n",
    "run_and_evaluate(\"resnet\", classes)  # 执行模型训练和评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ad19b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vgg_model(model, device, train_loader, val_loader, criterion, optimizer, num_epochs=10):  # 定义 VGG 的独立训练函数\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):  # 加 tqdm 显示训练进度\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "        train_accs.append(correct / total)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        val_accs.append(val_correct / val_total)\n",
    "\n",
    "        print(f\"[VGG] Epoch {epoch+1}/{num_epochs} - Train Acc: {train_accs[-1]:.4f} - Val Acc: {val_accs[-1]:.4f}\")\n",
    "\n",
    "    import matplotlib.pyplot as plt  # 导入库\n",
    "    import numpy as np  # 导入库\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label=\"Train Loss\", c=\"red\")\n",
    "    plt.plot(val_losses, label=\"Val Loss\", c=\"blue\")\n",
    "    plt.xlabel(\"Epochs\"); plt.ylabel(\"Loss\"); plt.legend(); plt.show()\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_accs, label=\"Train Acc\", c=\"orangered\")\n",
    "    plt.plot(val_accs, label=\"Val Acc\", c=\"green\")\n",
    "    plt.xlabel(\"Epochs\"); plt.ylabel(\"Accuracy\"); plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103beaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = initialize_model(\"vgg\", num_classes=len(classes))[0].to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(vgg_model.parameters(), lr=config[\"learning_rate\"])  # 设置模型训练的超参数\n",
    "\n",
    "train_vgg_model(vgg_model, device, train_loader, test_loader, criterion, optimizer, num_epochs=config[\"num_epochs\"]) # 设置模型训练的超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3ed68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 使用 evaluate_model 函数评估 VGG 模型分类表现\n",
    "print(\"\\n==================== VGG Evaluation Metrics ====================\")\n",
    "evaluate_model(vgg_model, test_loader, device, class_names=classes)\n",
    "plt.title(f\"Confusion Matrix for VGG16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717ba179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # 导入库\n",
    "import cv2  # 导入库\n",
    "import torch  # 导入库\n",
    "import numpy as np  # 导入库\n",
    "import matplotlib.pyplot as plt  # 导入库\n",
    "from collections import defaultdict\n",
    "from torchcam.methods import GradCAM\n",
    "\n",
    "def overlay_heatmap(img: np.ndarray, cam: np.ndarray, alpha: float = 0.5) -> np.ndarray:\n",
    "    cam_uint8 = np.uint8(255 * cam)\n",
    "    heatmap = cv2.applyColorMap(cam_uint8, cv2.COLORMAP_JET)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "    if img.max() > 1.0:\n",
    "        img = np.float32(img) / 255\n",
    "    if img.shape[:2] != heatmap.shape[:2]:\n",
    "        heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    overlayed = heatmap * alpha + img\n",
    "    overlayed = overlayed / np.max(overlayed)\n",
    "    return np.uint8(255 * overlayed)\n",
    "\n",
    "def unnormalize(tensor, mean, std):\n",
    "    for t, m, s in zip(tensor, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    return tensor\n",
    "\n",
    "def apply_gradcam_all_classes(model, device, dataloader, model_name=\"resnet\", save_dir=\"gradcam_outputs\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    model.eval()\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        target_layer = model.layer4[-1].conv2\n",
    "    elif model_name == \"vgg\":\n",
    "        target_layer = model.features[-1]\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model\")\n",
    "\n",
    "    cam_extractor = GradCAM(model, target_layer=target_layer)\n",
    "\n",
    "    seen_classes = defaultdict(int)\n",
    "    total_target_classes = 15\n",
    "    class_id_to_name = [\n",
    "        \"Agriculture\", \"Airport\", \"Beach\", \"City\", \"Desert\", \"Forest\", \"Grassland\", \"Highway\",\n",
    "        \"Lake\", \"Mountain\", \"Parking\", \"Port\", \"Railway\", \"Residential\", \"River\"\n",
    "    ]\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        for i in range(inputs.shape[0]):\n",
    "            label = labels[i].item()\n",
    "            if seen_classes[label] >= 1:\n",
    "                continue \n",
    "\n",
    "            img_tensor = inputs[i].unsqueeze(0)\n",
    "            output = model(img_tensor)\n",
    "            class_idx = torch.argmax(output).item()\n",
    "\n",
    "            cam_tensor = cam_extractor(class_idx=class_idx, scores=output)[0]\n",
    "            cam = cam_tensor.cpu().numpy()\n",
    "            if cam.ndim == 3:\n",
    "                cam = cam[0]\n",
    "            cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n",
    "\n",
    "            unnorm_img_tensor = unnormalize(img_tensor.squeeze(0).cpu(),\n",
    "                                            mean=[0.485, 0.456, 0.406],\n",
    "                                            std=[0.229, 0.224, 0.225])\n",
    "            raw_image = np.clip(unnorm_img_tensor.permute(1, 2, 0).numpy(), 0, 1)\n",
    "\n",
    "            cam = cv2.resize(cam, (raw_image.shape[1], raw_image.shape[0]))\n",
    "            result = overlay_heatmap(raw_image, cam)\n",
    "            result_rgb = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            orig_img = np.uint8(raw_image * 255)\n",
    "            orig_bgr = cv2.cvtColor(orig_img, cv2.COLOR_RGB2BGR)\n",
    "            result_bgr = cv2.cvtColor(result_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            cname = class_id_to_name[label]\n",
    "            cv2.imwrite(os.path.join(save_dir, f\"{cname}_original.png\"), orig_bgr)\n",
    "            cv2.imwrite(os.path.join(save_dir, f\"{cname}_gradcam.png\"), result_bgr)\n",
    "            cv2.imwrite(os.path.join(save_dir, f\"{cname}_compare.png\"), np.hstack((orig_bgr, result_bgr)))\n",
    "\n",
    "            fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "            axs[0].imshow(orig_img)\n",
    "            axs[0].set_title(f\"{cname} - Original\")\n",
    "            axs[0].axis('off')\n",
    "            axs[1].imshow(result_rgb)\n",
    "            axs[1].set_title(f\"{cname} - GradCAM (Pred: {class_id_to_name[class_idx]})\")\n",
    "            axs[1].axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            seen_classes[label] += 1\n",
    "\n",
    "        if len(seen_classes) >= total_target_classes:\n",
    "            print(\"✅ 已为所有类别生成 Grad-CAM 可视化。\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0021b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_gradcam_all_classes(model, device, test_loader, model_name=\"resnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c429cf6f",
   "metadata": {},
   "source": [
    "\n",
    "## 🧪 模型鲁棒性对比评估：ResNet vs VGG\n",
    "\n",
    "我们使用 `occluded_test_transform`（中心遮挡 + 归一化）对两个模型进行评估，比较它们在遮挡图像上的分类性能，包括：\n",
    "- 准确率（Accuracy）\n",
    "- 精确率 / 召回率 / F1 分数（Precision / Recall / F1-score）\n",
    "\n",
    "通过这个实验可以观察不同架构的鲁棒性差异。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2439dd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ✅ 构建遮挡数据加载器\n",
    "occluded_dataset = CustomDataset(test_images, test_labels, transform=occluded_test_transform)\n",
    "occluded_loader = DataLoader(occluded_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# ✅ 对 ResNet 模型在遮挡数据上评估\n",
    "print(\"🔍 ResNet under Occlusion\")\n",
    "evaluate_model(resnet_model, occluded_loader, device, class_names=classes)\n",
    "\n",
    "# ✅ 对 VGG 模型在遮挡数据上评估\n",
    "print(\"\\n🔍 VGG under Occlusion\")\n",
    "evaluate_model(vgg_model, occluded_loader, device, class_names=classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57d87c6",
   "metadata": {},
   "source": [
    "\n",
    "## 🔁 交叉验证（Cross-Validation）支持\n",
    "\n",
    "为了增强模型性能评估的稳健性，我们可以使用 **5-fold 交叉验证（5-Fold CV）**。\n",
    "- 将整个训练数据划分为 5 个子集（folds）\n",
    "- 每次选择其中一个作为验证集，其他 4 个作为训练集\n",
    "- 训练 5 次，计算平均准确率和 F1-score\n",
    "\n",
    "这避免了单一训练/验证划分导致的偶然偏差，提升模型评估的可靠性。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae93fe44",
   "metadata": {},
   "source": [
    "\n",
    "## 📈 每折训练过程可视化（Loss & Accuracy）\n",
    "\n",
    "为了观察模型在每一折训练/验证过程中的稳定性，我们记录了每一折的训练与验证 Loss/Accuracy 曲线。\n",
    "这有助于判断：\n",
    "- 模型是否存在过拟合或欠拟合\n",
    "- 不同折之间训练过程是否稳定一致\n",
    "- 模型在少量数据上的泛化能力是否良好\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf6c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acc_list, f1_list = [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(image_paths, labels)):\n",
    "    print(f\"📂 Fold {fold+1}/5\")\n",
    "    \n",
    "    X_train, y_train = image_paths[train_idx], labels[train_idx]\n",
    "    X_val, y_val = image_paths[val_idx], labels[val_idx]\n",
    "\n",
    "    train_ds = CustomDataset(X_train, y_train, transform=train_transform)\n",
    "    val_ds = CustomDataset(X_val, y_val, transform=test_transform)\n",
    "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = initialize_model(\"vgg\", num_classes=len(classes))[0].to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "    # 每折都记录曲线\n",
    "    history = {'train_loss': [], 'test_loss': [], 'train_acc': [], 'test_acc': []}\n",
    "\n",
    "    for epoch in range(5):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        history['train_loss'].append(running_loss / len(train_loader))\n",
    "        history['train_acc'].append(correct / total)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "        history['test_loss'].append(val_loss / len(val_loader))\n",
    "        history['test_acc'].append(val_correct / val_total)\n",
    "\n",
    "    # 绘制每折训练/验证曲线\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(history['train_loss'], label='Train Loss', c='red')\n",
    "    plt.plot(history['test_loss'], label='Val Loss', c='blue')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Loss')\n",
    "    plt.title(f'Fold {fold+1} - Loss Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(history['train_acc'], label='Train Acc', c='orangered')\n",
    "    plt.plot(history['test_acc'], label='Val Acc', c='green')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n",
    "    plt.title(f'Fold {fold+1} - Accuracy Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # 记录评估指标\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_true.extend(targets.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    acc_list.append(acc)\n",
    "    f1_list.append(f1)\n",
    "    print(f\"Fold {fold+1} Accuracy: {acc:.4f}, F1-score: {f1:.4f}\\n\")\n",
    "\n",
    "print(\"✅ 平均准确率:\", np.mean(acc_list))\n",
    "print(\"✅ 平均加权F1分数:\", np.mean(f1_list))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
